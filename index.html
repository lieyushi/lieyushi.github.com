<!doctype html>
<html>
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Huikun Bi </title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <p><small><a href="https://lieyushi.github.io/index.html"></a></p>
        <h1>Lieyu Shi</h1>
        <img src="research/lieyushi.jpeg" height="180" width="180">
        <p><br>Ph.D. Candidate at <br>Depart of Computer Science, <br>University of Houston, <br>Houston, TX, USA</br></p>
<!--         <p>Research Affiliate<br><a href="http://legacy.iza.org/en/webcontent/personnel/photos/index_html?key=24155">Institute for the Study of Labor (IZA)</a></p> -->
<!--     <h3><p class="view"><a href="https://huikunbi.github.io/">Home</a></p></h3> -->
<!--         <h3><p class="view"><a href="https://huikunbi.github.io/index.html">Research</a></p></h3> -->
    <h3><p class="view"><a href="https://lieyushi.github.io/research/lieyushi_resume.pdf">CV</a></p></h3>  
<!--         <h3><p class="view"><a href="https://huikunbi.github.io/code.html">Code</a></p></h3> 
        <h3><p class="view"><a href="https://huikunbi.github.io/teaching.html">Teaching</a></p></h3> 
        <h3><p class="view"><a href="https://huikunbi.github.io/personal.html">Personal</a></p></h3> -->
    <p class="view"><b>Social</b><br>
        <a href="mailto:shilieyu91@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a> shilieyu91@gmail.com<br>
<!--         <a href="https://scholar.google.com/citations?user=eohlTTcAAAAJ&hl=en" target="_blank"><i class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br>
        <a href="https://orcid.org/0000-0002-6910-0363"><i class="ai ai-fw ai-orcid-square"></i> ORCID</a><br>
        <a href="http://ideas.repec.org/f/pra541.html"><i class="fa fa-fw fa-share-alt-square"></i> RePEc</a><br>-->
        <a href="https://github.com/lieyushi"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
<!--        <a href="http://twitter.com/huikunbi" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br> -->
        <a href="https://www.linkedin.com/in/lieyu-shi-1b377568/" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br>

      </header>
      <section>

    <h3>About me</h3>
      <p>
      I am a Ph.D. candidate in computer science department from <a href="http://uh.edu/">University of Houston</a>, TX, USA. I'm to graduate in December 2019 and actively seeking software engineer position. Before that, I got the B.S. in Computational Mathematics from <a href="http://men.xjtu.edu.cn/">Xi'an Jiaotong University</a> in July 2013.         
      </p>
          
      <p>
      My research primarily centers on flow visualization and analysis, especially the feature estimation from integral curves of input with unsupervised clustering techniques.
          
      </p>
          
    
        <hr>
<!--  -------------------------------------------------------        -->
<!--    <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset</h2>

  <!--  -----------------------------------------------------------------     -->
<!--       <p>
        <p style="margin:0;" }><p > 
          Dataset-Name
          <br>I built a large dataset containing the trajectories of vehicles and pedestrians in vehicle-pedestrian-mixed scenes. Please contact me for more details. -->
    <!--        <br>IEEE Transactions on Visualization and Computer Graphics (TVCG), accepted in December 2018 
       -->
      
     
    
<!--     </p>
    </p>
  </p>

     <hr>    --> 
<!--  -----------------------------------------------------------------     -->

   <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h2>

        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/8834822">
          Integral Curve Clustering and Simplification for Flow Visualization: A Comparative Evaluation</a> 
          <br><b> Lieyu Shi </b>, Robert Laramee and Guoning Chen. 
          <br>IEEE Transactions on Visualization and Computer Graphics 2019 (accepted)
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="http://www2.cs.uh.edu/~chengu/Publications/CurveClusteringEvl/CurveClusteringEvl_TVCG.pdf">paper</a>  ]

      [ <a style="margin:0; font-size:100%; font-weight:bold" href="http://www2.cs.uh.edu/~chengu/Publications/CurveClusteringEvl/CurveClusteringEvl_TVCG_supplemental.pdf">supplemental</a> 
      ]

      [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://github.com/lieyushi/FlowCurveClustering">source code</a> 
      ]
        
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Unsupervised clustering techniques have been widely applied to flow simulation data to alleviate clutter and occlusion in the
resulting visualization. However, there is an absence of systematic guidelines for users to evaluate (both quantitatively and visually) the appropriate clustering technique and similarity measures for streamline and pathline curves. In this work, we provide an overview of a number of prevailing curve clustering techniques. We then perform a comprehensive experimental study to qualitatively and quantitatively compare these clustering techniques coupled with popular similarity measures used in the flow visualization literature. Based on our experimental results, we derive empirical guidelines for selecting the appropriate clustering technique and similarity measure given the requirements of the visualization task. We believe our work will inform the task of generating meaningful reduced representations for large-scale flow data and inspire the continuous investigation of a more refined guidance on clustering technique selection. </div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
        
        
        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="hhttps://www.semanticscholar.org/paper/Metric-based-Curve-Clustering-and-Feature-in-Flow-Shi-Chen/770fba00e315f943a99be42ed67d2748f3bf1633">
          Metric-based Curve Clustering and Feature Extraction in Flow Visualization</a> 
          <br><b> Lieyu Shi </b> and Guoning Chen. 
          <br>IEEE CAD & Graphics 2017 short paper
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="http://www2.cs.uh.edu/~chengu/Publications/3DFlowVis/curveClustering.pdf">paper</a> 
      ]
        [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/Joint Prediction for Kinematic Trajectories in Vehicle-Pedestrian-Mixed Scenes-supp.pdf">supplemental</a> 
      ]
          [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.youtube.com/watch?v=AlBiVGr0Cw4&t=2s">video</a> 
      ]
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Trajectory prediction for objects is challenging and critical for various applications (e.g., autonomous driving, and anomaly detection). Most of the existing methods focus on homogeneous pedestrian trajectories prediction, where pedestrians are treated as particles without size. However, they fall short of handling crowded vehicle-pedestrian-mixed scenes directly since vehicles, limited with kinematics in reality, should be treated as rigid, non-particle objects ideally. In this paper, we tackle this problem using separate LSTMs for heterogeneous vehicles and pedestrians. Specifically, we use an oriented bounding box to represent each vehicle, calculated based on its position and orientation, to denote its kinematic trajectories. We then propose a framework called VP-LSTM to predict the kinematic trajectories of both vehicles and pedestrians simultaneously. In order to evaluate our model, a large dataset containing the trajectories of both vehicles and pedestrians in vehicle-pedestrian-mixed scenes is specially built. Through comparisons between our method with state-of-the-art approaches, we show the effectiveness and advantages of our method on kinematic trajectories prediction in vehicle-pedestrian-mixed scenes.</div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
        
        
        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/2019ICCV_STGAT.pdf">
          STGAT: Modeling Spatial-Temporal Interactions for Human Trajectory Prediction</a> 
          <br>Yingfan Huang, <b> Huikun Bi </b>, Zhaoxin Li , Tianlu Mao, Zhaoqi Wang. 
          <br>International Conference in Computer Vision (<b>ICCV</b> 2019), <b>oral</b> presentation  
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/2019ICCV_STGAT.pdf">paper</a> 
      ]
        
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Human trajectory prediction is challenging and critical in various applications (e.g., autonomous vehicles and social robots). Because of the continuity and foresight of the pedestrian movements, the moving pedestrians in crowded spaces will consider both spatial and temporal interactions to avoid future collisions. However, most of the existing methods ignore the temporal correlations of interactions with other pedestrians involved in a scene. In this work, we propose a Spatial-Temporal Graph Attention network (STGAT), based on a sequence-to-sequence architecture to predict future trajectories of pedestrians. Besides the spatial interactions captured by the graph attention mechanism at each time-step, we adopt an extra LSTM to encode the temporal correlations of interactions. Through comparisons with state-of-the-art methods, our model achieves superior performance on two publicly available crowd datasets (ETH and UCY) and produces more "socially" plausible trajectories for pedestrians.</div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
        
        
        
        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/EG_STAR___A_Survey_on_Visual_Traffic_Simulation_and_Animation.pdf">
          A Survey on Visual Traffic Simulation: Models, Evaluations, and Applications in Autonomous Driving</a> 
          <br>Qianwen Chao*, <b> Huikun Bi* (* indicates equal contribution)</b>, Weizi Li, Tianlu Mao, Zhaoqi Wang, Ming C. Lin, Zhigang Deng. 
          <br>Computer Graphics Forum, (<b>CGF</b>, accepted in June 2019)  
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/EG_STAR___A_Survey_on_Visual_Traffic_Simulation_and_Animation.pdf">paper</a> 
      ]
        
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Virtualized traffic via various simulation models and real-world traffic data are promising approaches to reconstruct detailed traffic flows. A variety of applications can benefit from the virtual traffic, including, but not limited to, video games, virtual reality, traffic engineering, and autonomous driving. In this survey, we provide a comprehensive review on the state-of-the-art techniques for traffic simulation and animation. We start with a discussion on three classes of traffic simulation models applied at different levels of detail. Then, we introduce various data-driven animation techniques, including existing data collection methods, and the validation and evaluation of simulated traffic flows. Next, We discuss how traffic simulations can benefit the training and testing of autonomous vehicles. Finally, we discuss the current states of traffic simulation and animation and suggest future research directions.</div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
<!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/SCA2016_lanechanging.pdf">
          A Deep Learning-based Framework for Intersectional Traffic Simulation and Editing</a> 
          <br><b> Huikun Bi</b>, Tianlu Mao, Zhaoqi Wang, Zhigang Deng. 
          <br>IEEE Transactions on Visualization and Computer Graphics (<b>TVCG</b>), accepted in December 2018 
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/A_Deep_Learning_based_Framework_for_Intersectional_Traffic_Simulation_and_Editing.pdf">paper</a> 
      ]
      [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://youtu.be/WvOS9spBZ-0">video</a>
      ]     
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Most of existing traffic simulation methods have been focused on simulating vehicles on freeways or city-scale urban networks. However, relatively little research has been done to simulate intersectional traffic to date despite its obvious importance in real-world traffic phenomena. In this paper we propose a novel deep learning-based framework to simulate and edit intersectional traffic. Specifically, based on an in-house collected intersectional traffic dataset, we employ the combination of convolution network (CNN) and recurrent network (RNN) to learn the patterns of vehicle trajectories in intersectional traffic. Besides simulating novel intersectional traffic, our method can be used to edit existing intersectional traffic. Through many experiments as well as comparison user studies, we demonstrate that the results by our method are visually indistinguishable from ground truth and perform better than other methods.
        </div></p>
<!--     <img src="research/2018tvcg.jpg" height="160" width="480">  -->
  </p>
 <!--  -----------------------------------------------------------------     -->
  <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/SCA2016_lanechanging.pdf">
          A Data-driven Model for Lane-changing in Traffic Simulation</a> 
          <br><b> Huikun Bi</b>, Tianlu Mao, Zhaoqi Wang, Zhigang Deng. 
<!--           <br> <i>Eurographics/ACM SIGGRAPH Symposium on Computer Animation,</i>2016  -->
          <br>Eurographics/ACM SIGGRAPH Symposium on Computer Animation (<b>SCA</b>), 2016 
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/SCA2016_lanechanging.pdf">paper</a> 
      ]
      [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.youtube.com/watch?v=qPqpmwZxM4s&feature=youtu.be">video</a>
      ]     
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> In this paper, we propose a new data-driven model to simulate the process of lane-changing in traffic simulation. Specifically, we first extract the features from surrounding vehicles that are relevant to the lane-changing of the subject vehicle. Then, we learn the lane-changing characteristics from the ground-truth vehicle trajectory data using randomized forest and back-propagation neural network algorithms. Our method can make the subject vehicle to take account of more gap options on the target lane to cut in as well as achieve more realistic lane-changing trajectories for the subject vehicle and the follower vehicle. Through many experiments and comparisons with selected state-of-the-art methods, we demonstrate that our approach can soundly outperform them in terms of the accuracy and quality of lane-changing simulation. Our model can be flexibly used together with a variety of existing car-following models to produce natural traffic animations in various virtual environments. </div></p>
<!--     <img src="research/sca.jpg" height="160" width="480"> -->
 </p>
 <!--  -----------------------------------------------------------------     -->
        
    
</section>
      
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script> 
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
