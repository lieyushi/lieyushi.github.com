<!doctype html>
<html>
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Huikun Bi </title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <p><small><a href="https://lieyushi.github.io/index.html"></a></p>
        <h1>Lieyu Shi</h1>
        <img src="research/WeChat Image_20181109174303.jpg" height="180" width="180">
        <p><br>Ph.D. Candidate at <br>Institute of Computing Technology, <br>Chinese Academy of Sciences, <br>Beijing, China</br></p>
<!--         <p>Research Affiliate<br><a href="http://legacy.iza.org/en/webcontent/personnel/photos/index_html?key=24155">Institute for the Study of Labor (IZA)</a></p> -->
<!--     <h3><p class="view"><a href="https://huikunbi.github.io/">Home</a></p></h3> -->
<!--         <h3><p class="view"><a href="https://huikunbi.github.io/index.html">Research</a></p></h3> -->
    <h3><p class="view"><a href="https://huikunbi.github.io/research/CV.pdf">CV</a></p></h3>  
<!--         <h3><p class="view"><a href="https://huikunbi.github.io/code.html">Code</a></p></h3> 
        <h3><p class="view"><a href="https://huikunbi.github.io/teaching.html">Teaching</a></p></h3> 
        <h3><p class="view"><a href="https://huikunbi.github.io/personal.html">Personal</a></p></h3> -->
    <p class="view"><b>Social</b><br>
        <a href="mailto:xiaobi361@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a> xiaobi361@gmail.com<br>
      <a href="mailto:xiaobi361@gmail.com" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a> bihuikun@ict.ac.cn<br>
<!--         <a href="https://scholar.google.com/citations?user=eohlTTcAAAAJ&hl=en" target="_blank"><i class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br>
        <a href="https://orcid.org/0000-0002-6910-0363"><i class="ai ai-fw ai-orcid-square"></i> ORCID</a><br>
        <a href="http://ideas.repec.org/f/pra541.html"><i class="fa fa-fw fa-share-alt-square"></i> RePEc</a><br>
        <a href="http://github.com/huikunbi"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
        <a href="http://twitter.com/huikunbi" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br> -->
        <a href="http://linkedin.com/in/huikunbi" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br>

    <p><b>Contact:</b><br>Institute of Computing Technology,<br>Chinese Academy of Sciences,<br>No.6 Kexueyuan South Road Zhongguancun,<br>Haidian District Beijing, 100190, China</p>
      </header>
      <section>

    <h3>About me</h3>
      <p>
      I am an assistant professor with Institute of Computing Technology, Chinese Academy of Sciences. I received my PhD degree from University of Chinese Academy of Sciences in 2019 under guidance of Prof. Zhaoqi Wang. I was a visiting professor in Prof. Zhigang Deng lab in University of Houston from Oct. 2015 to Dec. 2018.          
      </p>
          
      <p>
      My research primarily centers on computer vision and computer graphics, especially visual traffic simulation, trajectory prediction with deep learning and autonomous driving.
          
      </p>
          
    
        <hr>
<!--  -------------------------------------------------------        -->
<!--    <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset</h2>

  <!--  -----------------------------------------------------------------     -->
<!--       <p>
        <p style="margin:0;" }><p > 
          Dataset-Name
          <br>I built a large dataset containing the trajectories of vehicles and pedestrians in vehicle-pedestrian-mixed scenes. Please contact me for more details. -->
    <!--        <br>IEEE Transactions on Visualization and Computer Graphics (TVCG), accepted in December 2018 
       -->
      
     
    
<!--     </p>
    </p>
  </p>

     <hr>    --> 
<!--  -----------------------------------------------------------------     -->

   <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h2>

        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="---.pdf">
          Vehicle Trajectory Prediction Using LSTMs with Spatial-Temporal Attention Mechanisms</a> 
          <br>Lei Lin, Weizi Li, <b> Huikun Bi </b>, and Lingqiao Qin. 
          <br>submitted to the IEEE Intelligent Transportation Systems Magazine (ITSM 2019)
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="---.pdf">paper</a> 
      ]
        
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Accurate vehicle trajectory prediction can benefit many Intelligent Transportation System (ITS) applications such as traffic simulation and advanced driver assistance system. This ability is pronounced with the emergence of autonomous vehicles, as they require the prediction of nearby agents' trajectories to navigate safely and efficiently. Recent studies based on deep learning have greatly improved prediction accuracy. However, one prominent issue is that these models often lack explainability. We alleviate this issue by proposing STA-LSTM, an LSTM model with spatial-temporal attention mechanisms. STA-LSTM not only outperforms other state-of-the-art models in prediction accuracy but also identifies the influence of historical trajectories and neighboring vehicles on the target vehicle via spatial-temporal attention weights. We provide analyses of the learned attention weights in various traffic scenarios based on target vehicle class, target vehicle location, and traffic density. An analysis showing that STA-LSTM can capture fine-grained lane-changing behaviors is also provided. </div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
        
        
        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/Joint Prediction for Kinematic Trajectories in Vehicle-Pedestrian-Mixed Scenes.pdf">
          Joint Prediction for Kinematic Trajectories in Vehicle-Pedestrian-Mixed Scenes</a> 
          <br><b> Huikun Bi </b>, Zhong Fang, Tianlu Mao, Zhaoqi Wang, Zhigang Deng. 
          <br>International Conference in Computer Vision (<b>ICCV</b> 2019)
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="http://vr.ict.ac.cn/vp-lstm">project page</a> 
      ]
          [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/Joint Prediction for Kinematic Trajectories in Vehicle-Pedestrian-Mixed Scenes.pdf">paper</a> 
      ]
        [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/Joint Prediction for Kinematic Trajectories in Vehicle-Pedestrian-Mixed Scenes-supp.pdf">supplemental</a> 
      ]
          [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.youtube.com/watch?v=AlBiVGr0Cw4&t=2s">video</a> 
      ]
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Trajectory prediction for objects is challenging and critical for various applications (e.g., autonomous driving, and anomaly detection). Most of the existing methods focus on homogeneous pedestrian trajectories prediction, where pedestrians are treated as particles without size. However, they fall short of handling crowded vehicle-pedestrian-mixed scenes directly since vehicles, limited with kinematics in reality, should be treated as rigid, non-particle objects ideally. In this paper, we tackle this problem using separate LSTMs for heterogeneous vehicles and pedestrians. Specifically, we use an oriented bounding box to represent each vehicle, calculated based on its position and orientation, to denote its kinematic trajectories. We then propose a framework called VP-LSTM to predict the kinematic trajectories of both vehicles and pedestrians simultaneously. In order to evaluate our model, a large dataset containing the trajectories of both vehicles and pedestrians in vehicle-pedestrian-mixed scenes is specially built. Through comparisons between our method with state-of-the-art approaches, we show the effectiveness and advantages of our method on kinematic trajectories prediction in vehicle-pedestrian-mixed scenes.</div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
        
        
        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/2019ICCV_STGAT.pdf">
          STGAT: Modeling Spatial-Temporal Interactions for Human Trajectory Prediction</a> 
          <br>Yingfan Huang, <b> Huikun Bi </b>, Zhaoxin Li , Tianlu Mao, Zhaoqi Wang. 
          <br>International Conference in Computer Vision (<b>ICCV</b> 2019), <b>oral</b> presentation  
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/2019ICCV_STGAT.pdf">paper</a> 
      ]
        
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Human trajectory prediction is challenging and critical in various applications (e.g., autonomous vehicles and social robots). Because of the continuity and foresight of the pedestrian movements, the moving pedestrians in crowded spaces will consider both spatial and temporal interactions to avoid future collisions. However, most of the existing methods ignore the temporal correlations of interactions with other pedestrians involved in a scene. In this work, we propose a Spatial-Temporal Graph Attention network (STGAT), based on a sequence-to-sequence architecture to predict future trajectories of pedestrians. Besides the spatial interactions captured by the graph attention mechanism at each time-step, we adopt an extra LSTM to encode the temporal correlations of interactions. Through comparisons with state-of-the-art methods, our model achieves superior performance on two publicly available crowd datasets (ETH and UCY) and produces more "socially" plausible trajectories for pedestrians.</div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
        
        
        
        <!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/EG_STAR___A_Survey_on_Visual_Traffic_Simulation_and_Animation.pdf">
          A Survey on Visual Traffic Simulation: Models, Evaluations, and Applications in Autonomous Driving</a> 
          <br>Qianwen Chao*, <b> Huikun Bi* (* indicates equal contribution)</b>, Weizi Li, Tianlu Mao, Zhaoqi Wang, Ming C. Lin, Zhigang Deng. 
          <br>Computer Graphics Forum, (<b>CGF</b>, accepted in June 2019)  
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/EG_STAR___A_Survey_on_Visual_Traffic_Simulation_and_Animation.pdf">paper</a> 
      ]
        
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Virtualized traffic via various simulation models and real-world traffic data are promising approaches to reconstruct detailed traffic flows. A variety of applications can benefit from the virtual traffic, including, but not limited to, video games, virtual reality, traffic engineering, and autonomous driving. In this survey, we provide a comprehensive review on the state-of-the-art techniques for traffic simulation and animation. We start with a discussion on three classes of traffic simulation models applied at different levels of detail. Then, we introduce various data-driven animation techniques, including existing data collection methods, and the validation and evaluation of simulated traffic flows. Next, We discuss how traffic simulations can benefit the training and testing of autonomous vehicles. Finally, we discuss the current states of traffic simulation and animation and suggest future research directions.</div></p>
<!--     <img src="research/EG_survey.png.jpg" height="180" width="480">  -->
  </p>       
  <!--  -----------------------------------------------------------------     -->
<!--  -----------------------------------------------------------------     -->
        <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/SCA2016_lanechanging.pdf">
          A Deep Learning-based Framework for Intersectional Traffic Simulation and Editing</a> 
          <br><b> Huikun Bi</b>, Tianlu Mao, Zhaoqi Wang, Zhigang Deng. 
          <br>IEEE Transactions on Visualization and Computer Graphics (<b>TVCG</b>), accepted in December 2018 
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/A_Deep_Learning_based_Framework_for_Intersectional_Traffic_Simulation_and_Editing.pdf">paper</a> 
      ]
      [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://youtu.be/WvOS9spBZ-0">video</a>
      ]     
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> 
Most of existing traffic simulation methods have been focused on simulating vehicles on freeways or city-scale urban networks. However, relatively little research has been done to simulate intersectional traffic to date despite its obvious importance in real-world traffic phenomena. In this paper we propose a novel deep learning-based framework to simulate and edit intersectional traffic. Specifically, based on an in-house collected intersectional traffic dataset, we employ the combination of convolution network (CNN) and recurrent network (RNN) to learn the patterns of vehicle trajectories in intersectional traffic. Besides simulating novel intersectional traffic, our method can be used to edit existing intersectional traffic. Through many experiments as well as comparison user studies, we demonstrate that the results by our method are visually indistinguishable from ground truth and perform better than other methods.
        </div></p>
<!--     <img src="research/2018tvcg.jpg" height="160" width="480">  -->
  </p>
 <!--  -----------------------------------------------------------------     -->
  <p>
        <p style="margin:0;" }><p > <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/SCA2016_lanechanging.pdf">
          A Data-driven Model for Lane-changing in Traffic Simulation</a> 
          <br><b> Huikun Bi</b>, Tianlu Mao, Zhaoqi Wang, Zhigang Deng. 
<!--           <br> <i>Eurographics/ACM SIGGRAPH Symposium on Computer Animation,</i>2016  -->
          <br>Eurographics/ACM SIGGRAPH Symposium on Computer Animation (<b>SCA</b>), 2016 
      
      <br>[ <a style="margin:0; font-size:100%; font-weight:bold" href="https://huikunbi.github.io/research/SCA2016_lanechanging.pdf">paper</a> 
      ]
      [ <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.youtube.com/watch?v=qPqpmwZxM4s&feature=youtu.be">video</a>
      ]     
      <button class="accordion">
      Abstract
    </button>
    </p>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"> In this paper, we propose a new data-driven model to simulate the process of lane-changing in traffic simulation. Specifically, we first extract the features from surrounding vehicles that are relevant to the lane-changing of the subject vehicle. Then, we learn the lane-changing characteristics from the ground-truth vehicle trajectory data using randomized forest and back-propagation neural network algorithms. Our method can make the subject vehicle to take account of more gap options on the target lane to cut in as well as achieve more realistic lane-changing trajectories for the subject vehicle and the follower vehicle. Through many experiments and comparisons with selected state-of-the-art methods, we demonstrate that our approach can soundly outperform them in terms of the accuracy and quality of lane-changing simulation. Our model can be flexibly used together with a variety of existing car-following models to produce natural traffic animations in various virtual environments. </div></p>
<!--     <img src="research/sca.jpg" height="160" width="480"> -->
 </p>
 <!--  -----------------------------------------------------------------     -->
        
    
</section>
      
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script> 
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
